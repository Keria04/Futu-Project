#!/usr/bin/env python3
"""
é…ç½®å‚æ•°ä¼˜åŒ–å™¨
ç”¨äºè‡ªåŠ¨å¯»æ‰¾æœ€ä½³çš„é…ç½®å‚æ•°ç»„åˆï¼Œä»¥è·å¾—æœ€ä½³æ€§èƒ½
"""

import sys
import os
import time
import json
import statistics
import itertools
from datetime import datetime
from PIL import Image
import numpy as np

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "backend")))

from config import config
from backend.model_module.feature_extractor import feature_extractor

class ConfigOptimizer:
    """é…ç½®å‚æ•°ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.original_config = {}
        self.backup_config()
        self.test_images = []
        self.optimization_results = {}
        
    def backup_config(self):
        """å¤‡ä»½åŸå§‹é…ç½®"""
        self.original_config = {
            'device': config.device,
            'batchsize': config.batchsize,
            'N_LIST': config.N_LIST,
            'DISTRIBUTED_AVAILABLE': config.DISTRIBUTED_AVAILABLE,
        }
        
    def restore_config(self):
        """æ¢å¤åŸå§‹é…ç½®"""
        for key, value in self.original_config.items():
            setattr(config, key, value)
            
    def generate_test_images(self, count=20):
        """ç”Ÿæˆæµ‹è¯•å›¾åƒ"""
        print(f"ç”Ÿæˆ {count} å¼ æµ‹è¯•å›¾åƒ...")
        self.test_images = []
        
        for i in range(count):
            color = (
                int(np.random.randint(0, 256)),
                int(np.random.randint(0, 256)),
                int(np.random.randint(0, 256))
            )
            img = Image.new('RGB', (224, 224), color=color)
            self.test_images.append(img)
            
        print(f"âœ… å·²ç”Ÿæˆ {len(self.test_images)} å¼ æµ‹è¯•å›¾åƒ")
        
    def evaluate_config(self, test_config, test_image_count=10):
        """è¯„ä¼°å•ä¸ªé…ç½®çš„æ€§èƒ½"""
        # åº”ç”¨é…ç½®
        for key, value in test_config.items():
            if hasattr(config, key):
                setattr(config, key, value)
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        test_batch = self.test_images[:test_image_count]
        
        try:
            # æ‰§è¡Œå¤šæ¬¡æµ‹è¯•å–å¹³å‡å€¼
            times = []
            for _ in range(3):
                start_time = time.time()
                features = feature_extractor(test_batch)
                end_time = time.time()
                times.append(end_time - start_time)
            
            avg_time = statistics.mean(times)
            throughput = len(test_batch) / avg_time
            per_image_time = avg_time / len(test_batch)
            
            return {
                'success': True,
                'avg_time': avg_time,
                'throughput': throughput,
                'per_image_time': per_image_time,
                'times': times,
                'images_processed': len(test_batch)
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
        
    def grid_search_optimization(self):
        """ç½‘æ ¼æœç´¢ä¼˜åŒ–"""
        print("\nğŸ” å¼€å§‹ç½‘æ ¼æœç´¢ä¼˜åŒ–...")
        print("="*60)
        
        # å®šä¹‰æœç´¢ç©ºé—´
        param_grid = {
            'device': ['cpu'],  # å¦‚æœæœ‰GPUå¯ä»¥æ·»åŠ  'cuda'
            'batchsize': [1, 4, 8, 16, 32, 64],
            'N_LIST': [1, 5, 10, 20],
        }
        
        # å¦‚æœæ”¯æŒGPUï¼Œæ·»åŠ GPUé€‰é¡¹
        try:
            import torch
            if torch.cuda.is_available():
                param_grid['device'].append('cuda')
                print("âœ… æ£€æµ‹åˆ°GPUï¼Œå°†æµ‹è¯•GPUé…ç½®")
        except ImportError:
            pass
        
        # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
        param_names = list(param_grid.keys())
        param_values = [param_grid[name] for name in param_names]
        param_combinations = list(itertools.product(*param_values))
        
        print(f"æ€»å…± {len(param_combinations)} ä¸ªé…ç½®ç»„åˆéœ€è¦æµ‹è¯•")
        
        results = []
        best_config = None
        best_throughput = 0
        
        for i, param_combo in enumerate(param_combinations):
            test_config = dict(zip(param_names, param_combo))
            
            print(f"\nè¿›åº¦: {i+1}/{len(param_combinations)} - æµ‹è¯•é…ç½®: {test_config}")
            
            result = self.evaluate_config(test_config)
            result['config'] = test_config
            results.append(result)
            
            if result['success']:
                throughput = result['throughput']
                print(f"  ååé‡: {throughput:.2f} å›¾åƒ/ç§’")
                
                if throughput > best_throughput:
                    best_throughput = throughput
                    best_config = test_config
                    print(f"  ğŸ¯ æ–°çš„æœ€ä½³é…ç½®!")
            else:
                print(f"  âŒ å¤±è´¥: {result['error']}")
        
        self.optimization_results['grid_search'] = {
            'results': results,
            'best_config': best_config,
            'best_throughput': best_throughput
        }
        
        return best_config, best_throughput
        
    def adaptive_optimization(self):
        """è‡ªé€‚åº”ä¼˜åŒ– - åŸºäºå½“å‰æœ€ä½³é…ç½®è¿›è¡Œå±€éƒ¨æœç´¢"""
        print("\nğŸ¯ å¼€å§‹è‡ªé€‚åº”ä¼˜åŒ–...")
        print("="*60)
        
        if 'grid_search' not in self.optimization_results:
            print("âŒ è¯·å…ˆè¿è¡Œç½‘æ ¼æœç´¢")
            return None, 0
        
        best_config = self.optimization_results['grid_search']['best_config']
        if not best_config:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„åŸºå‡†é…ç½®")
            return None, 0
        
        print(f"åŸºå‡†é…ç½®: {best_config}")
        
        current_config = best_config.copy()
        current_throughput = self.optimization_results['grid_search']['best_throughput']
        
        # è‡ªé€‚åº”æœç´¢æ‰¹å¤„ç†å¤§å°
        print("\nä¼˜åŒ–æ‰¹å¤„ç†å¤§å°...")
        batchsize = current_config['batchsize']
        
        # å‘ä¸Šæœç´¢
        for new_batchsize in [batchsize * 2, batchsize * 4]:
            if new_batchsize > 128:  # è®¾ç½®ä¸Šé™
                break
                
            test_config = current_config.copy()
            test_config['batchsize'] = new_batchsize
            
            print(f"  æµ‹è¯•æ‰¹å¤„ç†å¤§å°: {new_batchsize}")
            result = self.evaluate_config(test_config)
            
            if result['success'] and result['throughput'] > current_throughput:
                current_config = test_config
                current_throughput = result['throughput']
                print(f"    âœ… æ”¹è¿›! æ–°ååé‡: {current_throughput:.2f}")
            else:
                print(f"    âŒ æ— æ”¹è¿›")
                break
        
        # å‘ä¸‹æœç´¢ï¼ˆå¦‚æœå‘ä¸Šæœç´¢æ²¡æœ‰æ”¹è¿›ï¼‰
        if current_config['batchsize'] == batchsize:
            for new_batchsize in [max(1, batchsize // 2), max(1, batchsize // 4)]:
                test_config = current_config.copy()
                test_config['batchsize'] = new_batchsize
                
                print(f"  æµ‹è¯•æ‰¹å¤„ç†å¤§å°: {new_batchsize}")
                result = self.evaluate_config(test_config)
                
                if result['success'] and result['throughput'] > current_throughput:
                    current_config = test_config
                    current_throughput = result['throughput']
                    print(f"    âœ… æ”¹è¿›! æ–°ååé‡: {current_throughput:.2f}")
                else:
                    print(f"    âŒ æ— æ”¹è¿›")
                    break
        
        # ä¼˜åŒ–ç°‡å¤§å°
        print("\nä¼˜åŒ–ç°‡å¤§å°...")
        n_list = current_config['N_LIST']
        
        for new_n_list in [n_list * 2, n_list // 2, n_list + 5, max(1, n_list - 5)]:
            if new_n_list <= 0 or new_n_list > 100:
                continue
                
            test_config = current_config.copy()
            test_config['N_LIST'] = new_n_list
            
            print(f"  æµ‹è¯•ç°‡å¤§å°: {new_n_list}")
            result = self.evaluate_config(test_config)
            
            if result['success'] and result['throughput'] > current_throughput:
                current_config = test_config
                current_throughput = result['throughput']
                print(f"    âœ… æ”¹è¿›! æ–°ååé‡: {current_throughput:.2f}")
        
        self.optimization_results['adaptive'] = {
            'final_config': current_config,
            'final_throughput': current_throughput
        }
        
        return current_config, current_throughput
        
    def benchmark_optimized_config(self, optimized_config):
        """å¯¹ä¼˜åŒ–åçš„é…ç½®è¿›è¡ŒåŸºå‡†æµ‹è¯•"""
        print("\nğŸ“Š å¯¹ä¼˜åŒ–é…ç½®è¿›è¡ŒåŸºå‡†æµ‹è¯•...")
        print("="*60)
        
        # æµ‹è¯•ä¸åŒå·¥ä½œè´Ÿè½½
        workloads = [
            {'name': 'è½»é‡çº§', 'image_count': 5},
            {'name': 'ä¸­ç­‰', 'image_count': 10},
            {'name': 'é‡è´Ÿè½½', 'image_count': 20}
        ]
        
        benchmark_results = {}
        
        for workload in workloads:
            print(f"\næµ‹è¯•å·¥ä½œè´Ÿè½½: {workload['name']} ({workload['image_count']} å›¾åƒ)")
            
            # åŸå§‹é…ç½®æµ‹è¯•
            self.restore_config()
            original_result = self.evaluate_config(self.original_config, workload['image_count'])
            
            # ä¼˜åŒ–é…ç½®æµ‹è¯•
            optimized_result = self.evaluate_config(optimized_config, workload['image_count'])
            
            if original_result['success'] and optimized_result['success']:
                improvement = optimized_result['throughput'] / original_result['throughput']
                time_saved = original_result['avg_time'] - optimized_result['avg_time']
                
                print(f"  åŸå§‹é…ç½®: {original_result['throughput']:.2f} å›¾åƒ/ç§’")
                print(f"  ä¼˜åŒ–é…ç½®: {optimized_result['throughput']:.2f} å›¾åƒ/ç§’")
                print(f"  æ”¹è¿›å€æ•°: {improvement:.2f}x")
                print(f"  æ—¶é—´èŠ‚çœ: {time_saved:.3f}s")
                
                benchmark_results[workload['name']] = {
                    'original': original_result,
                    'optimized': optimized_result,
                    'improvement': improvement,
                    'time_saved': time_saved
                }
            else:
                print(f"  âŒ æµ‹è¯•å¤±è´¥")
                benchmark_results[workload['name']] = {'error': 'æµ‹è¯•å¤±è´¥'}
        
        return benchmark_results
        
    def generate_optimization_report(self):
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š...")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_dir = os.path.join("..", "performance_reports", f"optimization_{timestamp}")
        os.makedirs(report_dir, exist_ok=True)
        
        # ä¿å­˜åŸå§‹æ•°æ®
        with open(os.path.join(report_dir, "optimization_results.json"), "w", encoding='utf-8') as f:
            json.dump(self.optimization_results, f, indent=2, ensure_ascii=False)
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        report_path = os.path.join(report_dir, "optimization_report.md")
        with open(report_path, "w", encoding='utf-8') as f:
            f.write("# é…ç½®ä¼˜åŒ–æŠ¥å‘Š\n\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # åŸå§‹é…ç½®
            f.write("## åŸå§‹é…ç½®\n\n")
            f.write("| å‚æ•° | å€¼ |\n")
            f.write("|------|----|\n")
            for key, value in self.original_config.items():
                f.write(f"| {key} | {value} |\n")
            f.write("\n")
            
            # ç½‘æ ¼æœç´¢ç»“æœ
            if 'grid_search' in self.optimization_results:
                grid_result = self.optimization_results['grid_search']
                f.write("## ç½‘æ ¼æœç´¢ç»“æœ\n\n")
                
                if grid_result['best_config']:
                    f.write("### æœ€ä½³é…ç½®\n\n")
                    f.write("| å‚æ•° | å€¼ |\n")
                    f.write("|------|----|\n")
                    for key, value in grid_result['best_config'].items():
                        f.write(f"| {key} | {value} |\n")
                    f.write(f"\næœ€ä½³ååé‡: {grid_result['best_throughput']:.2f} å›¾åƒ/ç§’\n\n")
                
                # Top 10 é…ç½®
                successful_results = [r for r in grid_result['results'] if r['success']]
                top_configs = sorted(successful_results, key=lambda x: x['throughput'], reverse=True)[:10]
                
                f.write("### Top 10 é…ç½®\n\n")
                f.write("| æ’å | è®¾å¤‡ | æ‰¹å¤„ç†å¤§å° | ç°‡å¤§å° | ååé‡(å›¾åƒ/s) |\n")
                f.write("|------|------|------------|--------|-----------------|\n")
                for i, result in enumerate(top_configs, 1):
                    config_info = result['config']
                    f.write(f"| {i} | {config_info['device']} | {config_info['batchsize']} | {config_info['N_LIST']} | {result['throughput']:.2f} |\n")
                f.write("\n")
            
            # è‡ªé€‚åº”ä¼˜åŒ–ç»“æœ
            if 'adaptive' in self.optimization_results:
                adaptive_result = self.optimization_results['adaptive']
                f.write("## è‡ªé€‚åº”ä¼˜åŒ–ç»“æœ\n\n")
                f.write("| å‚æ•° | å€¼ |\n")
                f.write("|------|----|\n")
                for key, value in adaptive_result['final_config'].items():
                    f.write(f"| {key} | {value} |\n")
                f.write(f"\næœ€ç»ˆååé‡: {adaptive_result['final_throughput']:.2f} å›¾åƒ/ç§’\n\n")
            
            # åŸºå‡†æµ‹è¯•ç»“æœ
            if 'benchmark' in self.optimization_results:
                benchmark_result = self.optimization_results['benchmark']
                f.write("## åŸºå‡†æµ‹è¯•å¯¹æ¯”\n\n")
                f.write("| å·¥ä½œè´Ÿè½½ | åŸå§‹ååé‡ | ä¼˜åŒ–ååé‡ | æ”¹è¿›å€æ•° | æ—¶é—´èŠ‚çœ(s) |\n")
                f.write("|----------|------------|------------|----------|-------------|\n")
                for workload_name, result in benchmark_result.items():
                    if 'error' not in result:
                        f.write(f"| {workload_name} | {result['original']['throughput']:.2f} | {result['optimized']['throughput']:.2f} | {result['improvement']:.2f}x | {result['time_saved']:.3f} |\n")
                    else:
                        f.write(f"| {workload_name} | N/A | N/A | N/A | N/A |\n")
                f.write("\n")
        
        print(f"âœ… ä¼˜åŒ–æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return report_path
        
    def run_full_optimization(self):
        """è¿è¡Œå®Œæ•´ä¼˜åŒ–æµç¨‹"""
        print("ğŸš€ å¼€å§‹é…ç½®å‚æ•°ä¼˜åŒ–")
        print("="*60)
        
        start_time = time.time()
        
        try:
            # ç”Ÿæˆæµ‹è¯•å›¾åƒ
            self.generate_test_images(count=20)
            
            # ç½‘æ ¼æœç´¢
            best_config, best_throughput = self.grid_search_optimization()
            
            if best_config:
                print(f"\nğŸ¯ ç½‘æ ¼æœç´¢æœ€ä½³é…ç½®: {best_config}")
                print(f"æœ€ä½³ååé‡: {best_throughput:.2f} å›¾åƒ/ç§’")
                
                # è‡ªé€‚åº”ä¼˜åŒ–
                final_config, final_throughput = self.adaptive_optimization()
                
                if final_config:
                    print(f"\nğŸ† æœ€ç»ˆä¼˜åŒ–é…ç½®: {final_config}")
                    print(f"æœ€ç»ˆååé‡: {final_throughput:.2f} å›¾åƒ/ç§’")
                    
                    # åŸºå‡†æµ‹è¯•
                    benchmark_results = self.benchmark_optimized_config(final_config)
                    self.optimization_results['benchmark'] = benchmark_results
                    
                    # ç”ŸæˆæŠ¥å‘Š
                    report_path = self.generate_optimization_report()
                    
                    # è®¡ç®—æ€»ä½“æ”¹è¿›
                    original_throughput = self.evaluate_config(self.original_config, 10)['throughput']
                    total_improvement = final_throughput / original_throughput if original_throughput > 0 else 0
                    
                    print(f"\nâœ… ä¼˜åŒ–å®Œæˆ!")
                    print(f"åŸå§‹æ€§èƒ½: {original_throughput:.2f} å›¾åƒ/ç§’")
                    print(f"ä¼˜åŒ–æ€§èƒ½: {final_throughput:.2f} å›¾åƒ/ç§’")
                    print(f"æ€»ä½“æ”¹è¿›: {total_improvement:.2f}x")
                    
                    total_time = time.time() - start_time
                    print(f"æ€»ä¼˜åŒ–æ—¶é—´: {total_time:.2f}ç§’")
                    
                    return final_config
                else:
                    print("âŒ è‡ªé€‚åº”ä¼˜åŒ–å¤±è´¥")
            else:
                print("âŒ ç½‘æ ¼æœç´¢å¤±è´¥ï¼Œæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆé…ç½®")
                
        except Exception as e:
            print(f"âŒ ä¼˜åŒ–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # æ¢å¤åŸå§‹é…ç½®
            self.restore_config()
            
        return None


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='é…ç½®å‚æ•°ä¼˜åŒ–å™¨')
    parser.add_argument('--mode', choices=['full', 'grid', 'adaptive'], default='full',
                      help='ä¼˜åŒ–æ¨¡å¼: full(å®Œæ•´ä¼˜åŒ–), grid(ä»…ç½‘æ ¼æœç´¢), adaptive(ä»…è‡ªé€‚åº”ä¼˜åŒ–)')
    
    args = parser.parse_args()
    
    optimizer = ConfigOptimizer()
    
    if args.mode == 'full':
        optimized_config = optimizer.run_full_optimization()
        if optimized_config:
            print(f"\nğŸ’¡ å»ºè®®å°†ä»¥ä¸‹é…ç½®å†™å…¥config.py:")
            for key, value in optimized_config.items():
                print(f"{key} = {repr(value)}")
    
    elif args.mode == 'grid':
        optimizer.generate_test_images()
        best_config, best_throughput = optimizer.grid_search_optimization()
        if best_config:
            print(f"\nğŸ¯ æœ€ä½³é…ç½®: {best_config}")
            print(f"æœ€ä½³ååé‡: {best_throughput:.2f} å›¾åƒ/ç§’")
    
    elif args.mode == 'adaptive':
        print("âŒ è‡ªé€‚åº”æ¨¡å¼éœ€è¦å…ˆè¿è¡Œç½‘æ ¼æœç´¢")


if __name__ == "__main__":
    main()
