"""
è®¡ç®—ç«¯å·¥ä½œè€… - ç­–ç•¥æ¨¡å¼ + å•ä¾‹æ¨¡å¼
è´Ÿè´£å¤„ç†è®¡ç®—ä»»åŠ¡
"""
import os
import sys
import time
import base64
import threading
from io import BytesIO
from typing import Any, Dict, List, Optional
from abc import ABC, abstractmethod
import logging
import json

from PIL import Image
import numpy as np

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from shared import redis_client, TaskMessage, TaskResult, TaskType, TaskStatus, MessageProtocol
from compute_service.model_module.feature_extractor import feature_extractor


class TaskProcessor(ABC):
    """ä»»åŠ¡å¤„ç†å™¨æ¥å£"""
    
    @abstractmethod
    def can_handle(self, task_type: TaskType) -> bool:
        """åˆ¤æ–­æ˜¯å¦èƒ½å¤„ç†è¯¥ç±»å‹ä»»åŠ¡"""
        pass
    
    @abstractmethod
    def process(self, task: TaskMessage) -> TaskResult:
        """å¤„ç†ä»»åŠ¡"""
        pass


class FeatureExtractionProcessor(TaskProcessor):
    """ç‰¹å¾æå–å¤„ç†å™¨"""
    
    def __init__(self):
        self.extractor = None
        self._lock = threading.Lock()
    
    def _get_extractor(self):
        """è·å–ç‰¹å¾æå–å™¨å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self.extractor is None:
            with self._lock:
                if self.extractor is None:
                    self.extractor = feature_extractor()
        return self.extractor
    
    def can_handle(self, task_type: TaskType) -> bool:
        """åˆ¤æ–­æ˜¯å¦èƒ½å¤„ç†è¯¥ç±»å‹ä»»åŠ¡"""
        return task_type in [TaskType.FEATURE_EXTRACTION, TaskType.BATCH_FEATURE_EXTRACTION]
    
    def process(self, task: TaskMessage) -> TaskResult:
        """å¤„ç†ç‰¹å¾æå–ä»»åŠ¡"""
        try:
            if task.task_type == TaskType.FEATURE_EXTRACTION:
                return self._process_single_image(task)
            elif task.task_type == TaskType.BATCH_FEATURE_EXTRACTION:
                return self._process_batch_images(task)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task.task_type}")
        
        except Exception as e:
            return MessageProtocol.create_error_result(
                task.task_id, 
                f"ç‰¹å¾æå–å¤±è´¥: {str(e)}"
            )
    def _process_single_image(self, task: TaskMessage) -> TaskResult:
        """å¤„ç†å•å¼ å›¾ç‰‡ç‰¹å¾æå–"""
        logger = logging.getLogger(f"{__name__}.FeatureExtractionProcessor")
        
        payload = task.payload
        image_data = payload.get('image_data')
        
        if not image_data:
            logger.error("âŒ ç¼ºå°‘å›¾ç‰‡æ•°æ®")
            raise ValueError("ç¼ºå°‘å›¾ç‰‡æ•°æ®")
        
        logger.debug(f"ğŸ–¼ï¸ å¼€å§‹å¤„ç†å•å¼ å›¾ç‰‡ç‰¹å¾æå–")
        
        # è§£ç å›¾ç‰‡
        try:
            img_bytes = base64.b64decode(image_data)
            img = Image.open(BytesIO(img_bytes))
            logger.debug(f"ğŸ“ å›¾ç‰‡å°ºå¯¸: {img.size}")
            logger.debug(f"ğŸ¨ å›¾ç‰‡æ¨¡å¼: {img.mode}")
        except Exception as e:
            logger.error(f"âŒ å›¾ç‰‡è§£ç å¤±è´¥: {e}")
            raise ValueError(f"å›¾ç‰‡è§£ç å¤±è´¥: {e}")
        
        # æå–ç‰¹å¾
        extractor = self._get_extractor()
        logger.debug(f"ğŸ” ä½¿ç”¨ç‰¹å¾æå–å™¨: {extractor.__class__.__name__}")
        
        start_time = time.time()
        features = extractor.calculate(img)
        extract_time = time.time() - start_time
        
        logger.debug(f"âœ… ç‰¹å¾æå–å®Œæˆï¼Œè€—æ—¶: {extract_time:.3f}s")
        logger.debug(f"ğŸ“Š ç‰¹å¾ç»´åº¦: {features.shape if hasattr(features, 'shape') else len(features)}")
        
        return MessageProtocol.create_success_result(
            task.task_id,
            features.tolist()
        )
    
    def _process_batch_images(self, task: TaskMessage) -> TaskResult:
        """å¤„ç†æ‰¹é‡å›¾ç‰‡ç‰¹å¾æå–"""
        payload = task.payload
        image_list = payload.get('image_list', [])
        
        if not image_list:
            raise ValueError("ç¼ºå°‘å›¾ç‰‡æ•°æ®åˆ—è¡¨")
        
        # è§£ç æ‰€æœ‰å›¾ç‰‡
        images = []
        for img_data in image_list:
            img_bytes = base64.b64decode(img_data)
            img = Image.open(BytesIO(img_bytes))
            images.append(img)
        
        # æ‰¹é‡æå–ç‰¹å¾
        extractor = self._get_extractor()
        features = extractor.calculate_batch(images)
        
        return MessageProtocol.create_success_result(
            task.task_id,
            features.tolist()
        )


class ComputeWorker:
    """è®¡ç®—ç«¯å·¥ä½œè€…"""
    def __init__(self, worker_name: str = "compute_worker", debug: bool = False):
        self.worker_name = worker_name
        self.debug = debug
        self.redis = redis_client.get_client()
        self.processors: List[TaskProcessor] = []
        self.running = False
        self.worker_thread = None
        self.logger = logging.getLogger(f"{__name__}.{worker_name}")
        
        if self.debug:
            self.logger.debug(f"ğŸ”§ åˆå§‹åŒ–è®¡ç®—å·¥ä½œè€…: {worker_name}")
        
        # æ³¨å†Œå¤„ç†å™¨
        self._register_processors()
    
    def _register_processors(self):
        """æ³¨å†Œä»»åŠ¡å¤„ç†å™¨"""
        self.processors.append(FeatureExtractionProcessor())
    
    def start(self):
        """å¯åŠ¨å·¥ä½œè€…"""
        if not self.running:
            self.running = True
            self.worker_thread = threading.Thread(target=self._work_loop)
            self.worker_thread.daemon = True
            self.worker_thread.start()
            logging.info(f"è®¡ç®—å·¥ä½œè€… {self.worker_name} å·²å¯åŠ¨")
    
    def stop(self):
        """åœæ­¢å·¥ä½œè€…"""
        self.running = False
        if self.worker_thread:
            self.worker_thread.join(timeout=5)
        logging.info(f"è®¡ç®—å·¥ä½œè€… {self.worker_name} å·²åœæ­¢")
    
    def _work_loop(self):
        """å·¥ä½œå¾ªç¯"""
        task_queue = "task_queue"
        result_queue = "result_queue"
        while self.running:
            try:
                if self.debug:
                    self.logger.debug(f"ğŸ” ç­‰å¾…ä»»åŠ¡...")
                
                # ä»ä¼˜å…ˆçº§é˜Ÿåˆ—è·å–ä»»åŠ¡
                task_data = self.redis.bzpopmin(task_queue, timeout=1)
                if not task_data:
                    if self.debug:
                        self.logger.debug("â° è¶…æ—¶ï¼Œç»§ç»­ç­‰å¾…...")
                    continue
                
                _, task_json, _ = task_data
                task = TaskMessage.from_json(task_json)
                
                if self.debug:
                    self.logger.debug(f"ğŸ“¥ æ”¶åˆ°ä»»åŠ¡: {task.task_id}")
                    self.logger.debug(f"ğŸ·ï¸ ä»»åŠ¡ç±»å‹: {task.task_type.value}")
                    self.logger.debug(f"ğŸ“Š ä»»åŠ¡æ•°æ®å¤§å°: {len(task_json)} bytes")
                
                self.logger.info(f"å¤„ç†ä»»åŠ¡: {task.task_id}, ç±»å‹: {task.task_type.value}")
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤„ç†ä¸­
                self._update_task_status(task.task_id, TaskStatus.PROCESSING)
                
                # æŸ¥æ‰¾åˆé€‚çš„å¤„ç†å™¨
                processor = self._find_processor(task.task_type)
                if processor is None:
                    if self.debug:
                        self.logger.debug(f"âŒ æ²¡æœ‰æ‰¾åˆ°å¤„ç†å™¨: {task.task_type.value}")
                    result = MessageProtocol.create_error_result(
                        task.task_id,
                        f"æ²¡æœ‰æ‰¾åˆ°å¤„ç†å™¨: {task.task_type.value}"
                    )
                else:
                    if self.debug:
                        self.logger.debug(f"âœ… æ‰¾åˆ°å¤„ç†å™¨: {processor.__class__.__name__}")
                    # å¤„ç†ä»»åŠ¡
                    start_time = time.time()
                    result = processor.process(task)
                    process_time = time.time() - start_time
                    
                    if self.debug:
                        self.logger.debug(f"â±ï¸ å¤„ç†è€—æ—¶: {process_time:.3f}s")
                
                # å‘é€ç»“æœ
                self.redis.lpush(result_queue, result.to_json())
                
                if self.debug:
                    self.logger.debug(f"ğŸ“¤ ç»“æœå·²å‘é€åˆ°é˜Ÿåˆ—")
                
                self.logger.info(f"ä»»åŠ¡å®Œæˆ: {task.task_id}, çŠ¶æ€: {result.status.value}")
                
            except Exception as e:
                self.logger.error(f"å·¥ä½œå¾ªç¯å‡ºé”™: {e}")
                if self.debug:
                    import traceback
                    self.logger.debug(f"é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
                time.sleep(1)
    
    def _find_processor(self, task_type: TaskType) -> Optional[TaskProcessor]:
        """æŸ¥æ‰¾ä»»åŠ¡å¤„ç†å™¨"""
        for processor in self.processors:
            if processor.can_handle(task_type):
                return processor
        return None
    
    def _update_task_status(self, task_id: str, status: TaskStatus):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        task_key = f"task:{task_id}"
        task_data = redis_client.get_json(task_key)
        if task_data:
            task_data['status'] = status.value
            redis_client.set_json(task_key, task_data, ex=3600)


def run_compute_worker():
    """è¿è¡Œè®¡ç®—å·¥ä½œè€…"""
    import argparse
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='è®¡ç®—ç«¯å·¥ä½œè€…')
    parser.add_argument('--debug', action='store_true', help='å¯ç”¨è¯¦ç»†debugè¾“å‡º')
    parser.add_argument('--log-level', default='INFO', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'])
    args, unknown = parser.parse_known_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    log_level = getattr(logging, args.log_level.upper())
    if args.debug:
        log_level = logging.DEBUG
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),  # ç¡®ä¿è¾“å‡ºåˆ°æ ‡å‡†è¾“å‡º
        ]
    )
    
    logger = logging.getLogger(__name__)
    
    if args.debug:
        logger.info("ğŸ› DEBUGæ¨¡å¼å·²å¯ç”¨")
        logger.debug(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
        logger.debug(f"Pythonè·¯å¾„: {sys.path}")
    
    # è®¾ç½®å·¥ä½œç›®å½•
    current_dir = os.getcwd()
    target_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "../.."))
    if current_dir != target_dir:
        logger.debug(f"åˆ‡æ¢å·¥ä½œç›®å½•: {current_dir} -> {target_dir}")
        os.chdir(target_dir)
    
    # åˆ›å»ºå·¥ä½œè€…
    worker = ComputeWorker(debug=args.debug)
    
    try:
        worker.start()
        
        # ä¿æŒè¿è¡Œ
        while True:
            time.sleep(1)
    
    except KeyboardInterrupt:
        logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·...")
    finally:
        worker.stop()
        logger.info("è®¡ç®—å·¥ä½œè€…å·²é€€å‡º")


if __name__ == '__main__':
    run_compute_worker()
