#!/usr/bin/env python3
"""
æµ‹è¯•æœç´¢åŠŸèƒ½ä¿®å¤çš„è„šæœ¬
éªŒè¯ç‰¹å¾æå–ä»»åŠ¡æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œ
"""

import requests
import os
import time
import json

def test_search_with_real_image():
    """æµ‹è¯•ä½¿ç”¨çœŸå®å›¾ç‰‡çš„æœç´¢åŠŸèƒ½"""
    print("=== æµ‹è¯•æœç´¢åŠŸèƒ½ä¿®å¤ ===")
    
    # å¯»æ‰¾æµ‹è¯•å›¾ç‰‡
    test_image_paths = [
        "datasets/1",
        "datasets/2",
        "datasets/3"
    ]
    
    test_image = None
    for dataset_path in test_image_paths:
        if os.path.exists(dataset_path):
            for root, dirs, files in os.walk(dataset_path):
                for file in files:
                    if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                        test_image = os.path.join(root, file)
                        break
                if test_image:
                    break
            if test_image:
                break
    
    if not test_image:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
        return False
    
    print(f"ğŸ“¸ ä½¿ç”¨æµ‹è¯•å›¾ç‰‡: {test_image}")
      # å‡†å¤‡æœç´¢è¯·æ±‚
    with open(test_image, 'rb') as f:
        files = {'query_img': f}
        data = {
            'dataset_names[]': ['1'],  # æœç´¢æ•°æ®é›†1
            'top_k': 5,
            'similarity_threshold': 30.0  # é™ä½é˜ˆå€¼ä»¥è·å¾—æ›´å¤šç»“æœ
        }
        
        print("ğŸš€ å‘é€æœç´¢è¯·æ±‚...")
        start_time = time.time()
        
        try:
            response = requests.post(
                'http://localhost:19198/api/search',
                files=files,
                data=data,
                timeout=60  # å¢åŠ è¶…æ—¶æ—¶é—´
            )
            
            end_time = time.time()
            print(f"â±ï¸  è¯·æ±‚è€—æ—¶: {end_time - start_time:.2f} ç§’")
            
            if response.status_code == 200:
                result = response.json()
                print("âœ… æœç´¢è¯·æ±‚æˆåŠŸ")
                
                if result.get('success'):
                    results = result.get('results', [])
                    print(f"ğŸ¯ æ‰¾åˆ° {len(results)} ä¸ªç›¸ä¼¼å›¾ç‰‡")
                    
                    for i, res in enumerate(results):
                        similarity = res.get('similarity', 0)
                        filename = res.get('fname', 'Unknown')
                        print(f"  {i+1}. {filename} - ç›¸ä¼¼åº¦: {similarity:.2f}%")
                    
                    # æ˜¾ç¤ºæœç´¢å‚æ•°
                    search_params = result.get('search_params', {})
                    print(f"ğŸ“‹ æœç´¢å‚æ•°: {json.dumps(search_params, indent=2, ensure_ascii=False)}")
                    
                    return True
                else:
                    print(f"âŒ æœç´¢å¤±è´¥: {result}")
                    return False
                
            else:
                print(f"âŒ æœç´¢è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                print(f"å“åº”å†…å®¹: {response.text}")
                return False
                
        except requests.exceptions.Timeout:
            print("âŒ è¯·æ±‚è¶…æ—¶ï¼Œå¯èƒ½è®¡ç®—ç«¯æœåŠ¡æœªæ­£å¸¸å“åº”")
            return False
        except requests.exceptions.RequestException as e:
            print(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}")
            return False

def check_compute_server_status():
    """æ£€æŸ¥è®¡ç®—ç«¯æœåŠ¡çŠ¶æ€"""
    print("\n=== æ£€æŸ¥è®¡ç®—ç«¯æœåŠ¡çŠ¶æ€ ===")
    
    # é€šè¿‡Redisæ£€æŸ¥è®¡ç®—ç«¯æ˜¯å¦åœ¨çº¿
    try:
        import redis
        r = redis.Redis(host='localhost', port=6379, decode_responses=True)
        
        # å‘é€å¥åº·æ£€æŸ¥ä»»åŠ¡
        import uuid
        task_id = str(uuid.uuid4())
        task_data = {
            'task_id': task_id,
            'task_type': 'health_check'
        }
        
        # å‘å¸ƒä»»åŠ¡
        r.publish('compute:health_check', json.dumps(task_data))
        print("âœ… å·²å‘é€å¥åº·æ£€æŸ¥ä»»åŠ¡")
        
        # ç­‰å¾…ç»“æœ
        for i in range(10):
            result = r.get(f"result:{task_id}")
            if result:
                result_data = json.loads(result)
                print(f"âœ… è®¡ç®—ç«¯æœåŠ¡æ­£å¸¸: {result_data}")
                return True
            time.sleep(0.5)
        
        print("âš ï¸  è®¡ç®—ç«¯æœåŠ¡æœªå“åº”å¥åº·æ£€æŸ¥")
        return False
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥è®¡ç®—ç«¯æœåŠ¡çŠ¶æ€å¤±è´¥: {e}")
        return False

def test_feature_extraction_directly():
    """ç›´æ¥æµ‹è¯•ç‰¹å¾æå–åŠŸèƒ½"""
    print("\n=== ç›´æ¥æµ‹è¯•ç‰¹å¾æå– ===")
    
    # å¯»æ‰¾æµ‹è¯•å›¾ç‰‡
    test_image = None
    for dataset_path in ["datasets/1", "datasets/2", "datasets/3"]:
        if os.path.exists(dataset_path):
            for root, dirs, files in os.walk(dataset_path):
                for file in files:
                    if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                        test_image = os.path.join(root, file)
                        break
                if test_image:
                    break
            if test_image:
                break
      if not test_image:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
        return False
    
    try:
        import redis
        r = redis.Redis(host='localhost', port=6379, decode_responses=True)
        
        # å‘é€ç‰¹å¾æå–ä»»åŠ¡
        import uuid
        task_id = str(uuid.uuid4())
        task_data = {
            'task_id': task_id,
            'task_type': 'single_feature_extraction',
            'image_path': os.path.abspath(test_image)
        }
        
        print(f"ğŸ“¸ æµ‹è¯•å›¾ç‰‡: {test_image}")
        print("ğŸš€ å‘é€ç‰¹å¾æå–ä»»åŠ¡...")
        
        # å‘å¸ƒä»»åŠ¡
        r.publish('compute:single_feature_extraction', json.dumps(task_data))
        
        # ç­‰å¾…ç»“æœ
        for i in range(30):  # ç­‰å¾…30ç§’
            result = r.get(f"result:{task_id}")
            if result:
                result_data = json.loads(result)
                if result_data.get('success'):
                    features = result_data.get('features', [])
                    print(f"âœ… ç‰¹å¾æå–æˆåŠŸï¼Œç‰¹å¾ç»´åº¦: {len(features)}")
                    return True
                else:
                    print(f"âŒ ç‰¹å¾æå–å¤±è´¥: {result_data.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    return False
            time.sleep(1)
            if i % 5 == 0:
                print(f"â³ ç­‰å¾…ä¸­... {i+1}/30 ç§’")
        
        print("âŒ ç‰¹å¾æå–è¶…æ—¶")
        return False
        
    except Exception as e:
        print(f"âŒ ç‰¹å¾æå–æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ”§ æœç´¢åŠŸèƒ½ä¿®å¤éªŒè¯")
    print("=" * 50)
    
    # 1. æ£€æŸ¥è®¡ç®—ç«¯æœåŠ¡çŠ¶æ€
    compute_ok = check_compute_server_status()
    
    # 2. ç›´æ¥æµ‹è¯•ç‰¹å¾æå–
    extraction_ok = test_feature_extraction_directly()
    
    # 3. æµ‹è¯•å®Œæ•´æœç´¢æµç¨‹
    search_ok = False
    if extraction_ok:
        search_ok = test_search_with_real_image()
    
    print("\n" + "=" * 50)
    print("ğŸ“‹ æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"  è®¡ç®—ç«¯æœåŠ¡çŠ¶æ€: {'âœ… æ­£å¸¸' if compute_ok else 'âŒ å¼‚å¸¸'}")
    print(f"  ç‰¹å¾æå–åŠŸèƒ½: {'âœ… æ­£å¸¸' if extraction_ok else 'âŒ å¼‚å¸¸'}")
    print(f"  æœç´¢åŠŸèƒ½: {'âœ… æ­£å¸¸' if search_ok else 'âŒ å¼‚å¸¸'}")
    
    if search_ok:
        print("\nğŸ‰ ä¿®å¤æˆåŠŸï¼æœç´¢åŠŸèƒ½å·²æ­£å¸¸å·¥ä½œã€‚")
    else:
        print("\nâš ï¸  ä»æœ‰é—®é¢˜éœ€è¦è§£å†³:")
        if not compute_ok:
            print("  - è®¡ç®—ç«¯æœåŠ¡æœªæ­£å¸¸å“åº”")
        if not extraction_ok:
            print("  - ç‰¹å¾æå–åŠŸèƒ½å¼‚å¸¸")
        print("  è¯·æ£€æŸ¥æ—¥å¿—è·å–æ›´å¤šä¿¡æ¯")
    
    return search_ok

if __name__ == '__main__':
    # æ”¹å˜å·¥ä½œç›®å½•åˆ°é¡¹ç›®æ ¹ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    os.chdir(script_dir)
    
    success = main()
    exit(0 if success else 1)
